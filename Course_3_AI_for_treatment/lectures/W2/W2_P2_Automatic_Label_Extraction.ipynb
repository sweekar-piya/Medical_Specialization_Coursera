{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this lecture, we will be studying about \"automatic label extraction\". Here, we will be using labelling a Chest X-Ray image dataset using \"Radiology Report\". (Refer to [What is Radiology Report](#what-is) section to understand what a inspection report looks like.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "\n",
    "In the field of medicine datasets are scarce; Even more scarce are labelled datasets.\n",
    "\n",
    "For to obtain labelled dataset, there are several methodologies which are:\n",
    "1. Annotation of data samples using experts (such as radiologist for labelling X-Rays.) where they actually inspect the raw data samples.\n",
    "\n",
    "    _However, this process of manual annotation would be time and cost intensive, rendering the process to be sub-optimal._\n",
    "\n",
    "    <figure>\n",
    "    <center><img src=\"../../assets/W2/W2_P2_annotation_methods_1.png\" width=900\">\n",
    "    <figcaption align=\"center\"> Fig 1: Annotation method 1: Use Expert for labelling data. </figcaption>\n",
    "    </figure>\n",
    "\n",
    "2. Annotation of data samples using non-expert where they inspect the report written by experts - for example: Radiologist write reports during interpretation of scans, such as X-ray, MRI, or CT, which contains the synopsis of the interpretation and highlights findings. \n",
    "\n",
    "    _Though less time-consuming then 1st option, this process is still manual and sub-optimal._\n",
    "\n",
    "    <figure>\n",
    "    <center><img src=\"../../assets/W2/W2_P2_annotation_methods_2.png\" width=900\">\n",
    "    <figcaption align=\"center\" align=\"center\"> Fig 2: Annotation method 2: Use inspection report for labelling data. </figcaption>\n",
    "    </figure>\n",
    "\n",
    "> Since the data labelling in cumbersome and time-consuming, __can we use AI to automate such labelling task?__\n",
    "\n",
    "3. Annotation of data samples using machines (multi-modal AI system), where the system takes inspection report and raw image and outputs the labels for the sample, i.e. _supervised ML problem_.\n",
    "\n",
    "    <figure>\n",
    "    <center><img src=\"../../assets/W2/W2_P2_annotation_methods_3.png\" width=900\">\n",
    "    <figcaption align=\"center\"> Fig 3: Annotation method 3: Use BERT for labelling data, as a supervised task. </figcaption>\n",
    "    </figure>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Radiology Report like?\n",
    "\n",
    "Radiologist after investigating a scan, here, Chest X-ray, will write an succint logs about the findings in a report, which is termed Radiology Report. Although, there is higher availability of radiology datasets, only few such dataset come with radiology reports attached such as [\\[1\\]](https://www.nature.com/articles/s41597-019-0322-0). An example from MIMIC-CXR dataset is shown below:\n",
    "\n",
    "<figure>\n",
    "<center><img src=\"https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs41597-019-0322-0/MediaObjects/41597_2019_322_Fig1_HTML.png\" align=\"middle\" width=700\">\n",
    "<figcaption> Fig 4: Example study contained in MIMIC-CXR. Above (a), the radiology report provides the interpretation of the image. PHI (public health information) has been removed and replaced with three underscores (_ _ _). Below, the two chest radiographs for this study are shown: (b) the frontal view (left image) and (c) the lateral view (right image). </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps for extraction of labels from radiology report\n",
    "\n",
    "1. Find \"Is the label mentioned in the report's summary/conclusion/impression?\"\n",
    "\n",
    "    In order to find if the label is mentioned in the report, we can directly search for the exact label or synonyms (list of words to match) in the report's text. Note: the label can be addressed as other words (synonyms) in the report, for example: the label `pneumonia` can be written in report as `pneumonia, infection, infectious proces, infectious`.\n",
    "\n",
    "    To find such a list of words to match with actual label, we can:\n",
    "    1. Ask a medical professional to write a list of synonyms. Or,\n",
    "    2. Use a Standard _Terminology_ (Thesaurus or Vocabularies), such as SNOMED CT, which contains ~300,000 concepts. Each \"concept\" for example: \"Common Cold\" contains __Synonyms__ and __Is-A relation__. \n",
    "\n",
    "    __INSERT FIGURES__ ABOUT TERMINOLOGY.\n",
    "\n",
    "2. Find \"Is the observation present or absent?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. Johnson, A.E.W., Pollard, T.J., Berkowitz, S.J. et al. MIMIC-CXR, a de-identified publicly available database of chest radiographs with free-text reports. Sci Data 6, 317 (2019). https://doi.org/10.1038/s41597-019-0322-0\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
